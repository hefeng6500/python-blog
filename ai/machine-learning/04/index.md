# 逻辑回归

## 逻辑回归简介

**学习目标：**

1.知道逻辑回归的应用场景

2.复习逻辑回归应用到的数学知识

### 【了解】应用场景

![image-20230904115156371](./images/image-20230904115156371.png)

逻辑回归是解决二分类问题的利器

### 【熟悉】数学知识

#### 【知道】sigmoid函数

![image-20230913152535607](./images/image-20230913152535607.png)

![image-20230904144434180](./images/image-20230904144434180.png)

![image-20230904144454316](./images/image-20230904144454316.png)



#### 【理解】概率

![image-20230904144658969](./images/image-20230904144658969.png)





#### 【理解】极大似然估计

核心思想：

设模型中含有待估参数w，可以取很多值。已经知道了样本观测值，从w的一切可能值中（选出一个使该观察值出现的概率为最大的值，作为w参数的估计值，这就是极大似然估计。（顾名思义：就是看上去那个是最大可能的意思）

举个例子：

假设有一枚不均匀的硬币，出现正面的概率和反面的概率是不同的。假定出现正面的概率为𝜃， 抛了6次得到如下现象 D = {正面，反面，反面，正面，正面，正面}。每次投掷事件都是相互独立的。 则根据产生的现象D，来估计参数𝜃是多少?

```
P(D|𝜃) = P {正面，反面，反面，正面，正面，正面}
 = P(正面|𝜃) P(正面|𝜃) P(正面|𝜃) P(正面|𝜃) P(正面|𝜃) P(正面|𝜃)

=𝜃 *(1-𝜃)*(1-𝜃)𝜃*𝜃*𝜃 = 𝜃4(1 − 𝜃)
```

问题转化为:求此函数的极大值时，估计𝜃为多少

![image-20230904145453737](./images/image-20230904145453737.png)



#### 【知道】对数函数



![image-20230904145530932](./images/image-20230904145530932.png)







## 逻辑回归原理

**学习目标**
1.理解逻辑回归算法的原理

2.知道逻辑回归的损失函数

### 【理解】原理

逻辑回归概念 Logistic Regression

• 一种分类模型，把线性回归的输出，作为逻辑回归的输入。 

• 输出是(0, 1)之间的值

• 基本思想

1. 利用线性模型 f(x) = wx + b 根据特征的重要性计算出一个值
2. 再使用 sigmoid 函数将 f(x) 的输出值映射为概率值
   1. 设置阈值(eg:0.5)，输出概率值大于 0.5，则将未知样本输出为 1 类
   2. 否则输出为 0 类

3.逻辑回归的假设函数
 h(w) = sigmoid(wx + b )

线性回归的输出，作为逻辑回归的输入

​      

**在逻辑回归中，当预测结果不对的时候，我们该怎么衡量其损失呢？**

我们来看下图(下图中，设置阈值为0.6)，

![image-20220121161828121](./images/image-20220121161828121.png) 

那么如何去衡量逻辑回归的预测结果与真实结果的差异？



### 【知道】损失函数

![image-20230904151300483](image-20230904151300483.png)



![image-20230904151334262](./images/image-20230904151334262.png)



![image-20230904151343779](./images/image-20230904151343779.png)





## 逻辑回归API

**学习目标：**

1.知道逻辑回归的API

2.动手实现癌症分类案例

### 【知道】API介绍

```python
sklearn.linear_model.LogisticRegression(solver='liblinear', penalty=‘l2’, C = 1.0)
```

**solver** **损失函数优化方法**:

训练速度:liblinear 对小数据集场景训练速度更快，sag 和 saga 对大数据集更快一些。 2 正则化:

1. newton-cg、lbfgs、sag、saga 支持 L2 正则化或者没有正则化
2. 2liblinear 和 saga 支持 L1 正则化

**penalty**:正则化的种类，l1 或者 l2

**C**:正则化力度

默认将类别数量少的当做正例



### 【实践】癌症分类案例

- 数据介绍

（1）699条样本，共11列数据，第一列用语检索的id，后9列分别是与肿瘤相关的医学特征，

​     最后一列表示肿瘤类型的数值。

（2）包含16个缺失值，用”?”标出。

（3）2表示良性，4表示恶性

> 数据描述
>
> （1）699条样本，共11列数据，第一列用语检索的id，后9列分别是与肿瘤
>
> 相关的医学特征，最后一列表示肿瘤类型的数值。
>
> （2）包含16个缺失值，用”?”标出。

​	

- 案例分析

```
1.获取数据
2.基本数据处理
2.1 缺失值处理
2.2 确定特征值,目标值
2.3 分割数据
3.特征工程(标准化)
4.机器学习(逻辑回归)
5.模型评估
```

- 代码实现

```python
# 0.导包
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import numpy as np

# 1.加载数据
data =pd.read_csv('breast-cancer-wisconsin.csv')
# print(data.info())
# 2.数据处理
# 2.1 缺失值
data =data.replace(to_replace='?',value=np.NAN)
data=data.dropna()

# 2.2 获取特征和目标值
X = data.iloc[:,1:-1]
y = data['Class']

# 2.3 数据划分
x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=22)
# 3.特征工程(标准化)
pre =StandardScaler()
x_train=pre.fit_transform(x_train)
x_test=pre.transform(x_test)

# 4.模型训练
model=LogisticRegression()
model.fit(x_train,y_train)

# 5.模型预测和评估
y_predict =model.predict(x_test)
print(y_predict)
print(accuracy_score(y_test,y_predict))

```



## 分类评估方法

**学习目标：**

1.理解混淆矩阵的构建方法

2.掌握精确率，召回率和F1score的计算方法

3.知道ROC曲线和AUC指标

### 【理解】混淆矩阵

![image-20230904162952115](./images/image-20230904162952115.png)

混淆矩阵作用在测试集样本集中：

1. 真实值是 **正例** 的样本中，被分类为 **正例** 的样本数量有多少，这部分样本叫做真正例（TP，True Positive）
2. 真实值是 **正例** 的样本中，被分类为 **假例** 的样本数量有多少，这部分样本叫做伪反例（FN，False Negative）
3. 真实值是 **假例** 的样本中，被分类为 **正例** 的样本数量有多少，这部分样本叫做伪正例（FP，False Positive）
4. 真实值是 **假例** 的样本中，被分类为 **假例** 的样本数量有多少，这部分样本叫做真反例（TN，True Negative）



> True Positive ：表示样本真实的类别
> Positive ：表示样本被预测为的类别


**例子：**

样本集中有 6 个恶性肿瘤样本，4 个良性肿瘤样本，我们假设恶性肿瘤为正例，则：

**模型 A：** 预测对了 3 个恶性肿瘤样本，4 个良性肿瘤样本

1. 真正例 TP 为：3 
2. 伪反例 FN 为：3
3. 伪正例 FP 为：0
4. 真反例 TN：4

**模型 B：** 预测对了 6 个恶性肿瘤样本，1个良性肿瘤样本

1. 真正例 TP 为：6
2. 伪反例 FN 为：0
3. 伪正例 FP 为：3
4. 真反例 TN：1



我们会发现：TP+FN+FP+TN = 总样本数量



### 【掌握】Precision（精确率）


精确率也叫做查准率，指的是对正例样本的预测准确率。比如：我们把恶性肿瘤当做正例样本，则我们就需要知道模型对恶性肿瘤的预测准确率。


<img src="./images/05.png" alt="image-20210709223432330" style="zoom:50%;" />



**例子：**

样本集中有 6 个恶性肿瘤样本，4 个良性肿瘤样本，我们假设恶性肿瘤为正例，则：

**模型 A：** 预测对了 3 个恶性肿瘤样本，4 个良性肿瘤样本

1. 真正例 TP 为：3 
2. 伪反例 FN 为：3
3. 假正例 FP 为：0
4. 真反例 TN：4
5. **精准率：3/(3+0) = 100%**



**模型 B：** 预测对了 6 个恶性肿瘤样本，1个良性肿瘤样本

1. 真正例 TP 为：6
2. 伪反例 FN 为：0
3. 假正例 FP 为：3
4. 真反例 TN：1
5. **精准率：6/(6+3) = 67%**





### 【掌握】Recall（召回率）


召回率也叫做查全率，指的是预测为真正例样本占所有真实正例样本的比重。例如：我们把恶性肿瘤当做正例样本，则我们想知道模型是否能把所有的恶性肿瘤患者都预测出来。


<img src="./images/06.png" />


**例子：**

样本集中有 6 个恶性肿瘤样本，4 个良性肿瘤样本，我们假设恶性肿瘤为正例，则：

**模型 A：** 预测对了 3 个恶性肿瘤样本，4 个良性肿瘤样本

1. 真正例 TP 为：3 
2. 伪反例 FN 为：3
3. 假正例 FP 为：0
4. 真反例 TN：4
5. **精准率：3/(3+0) = 100%**
6. **召回率：3/(3+3)=50%**

**模型 B：** 预测对了 6 个恶性肿瘤样本，1个良性肿瘤样本

1. 真正例 TP 为：6
2. 伪反例 FN 为：0
3. 假正例 FP 为：3
4. 真反例 TN：1
5. **精准率：6/(6+3) = 67%**
6. **召回率：6/(6+0)= 100%** 



###  【掌握】F1-score

如果我们对模型的精度、召回率都有要求，希望知道模型在这两个评估方向的综合预测能力如何？则可以使用 F1-score 指标。

<img src="./images/07.png" />

样本集中有 6 个恶性肿瘤样本，4 个良性肿瘤样本，我们假设恶性肿瘤为正例，则：

**模型 A：** 预测对了 3 个恶性肿瘤样本，4 个良性肿瘤样本



1. 真正例 TP 为：3 
2. 伪反例 FN 为：3
3. 假正例 FP 为：0
4. 真反例 TN：4
5. **精准率：3/(3+0) = 100%**
6. **召回率：3/(3+3)=50%**
7. **F1-score：(2\*3)/(2\*3+3+0)=67%**

**模型 B：** 预测对了 6 个恶性肿瘤样本，1个良性肿瘤样本

1. 真正例 TP 为：6
2. 伪反例 FN 为：0
3. 假正例 FP 为：3
4. 真反例 TN：1
5. **精准率：6/(6+3) = 67%**
6. **召回率：6/(6+0)= 100%** 
7. **F1-score：(2\*6)/(2\*6+0+3)=80%**


###  【知道】ROC曲线和AUC指标

####  ROC 曲线

ROC 曲线：我们分别考虑正负样本的情况：

1. 正样本中被预测为正样本的概率，即：TPR （True Positive Rate）
2. 负样本中被预测为正样本的概率，即：FPR （False Positive Rate）

![image-20230904182146483](./images/image-20230904182146483.png)

ROC 曲线图像中，4 个特殊点的含义：



1. (0, 0) 表示所有的正样本都预测为错误，所有的负样本都预测正确
2. (1, 0) 表示所有的正样本都预测错误，所有的负样本都预测错误
3. (1, 1) 表示所有的正样本都预测正确，所有的负样本都预测错误
4. (0, 1) 表示所有的正样本都预测正确，所有的负样本都预测正确



#### 绘制 ROC 曲线

假设：在网页某个位置有一个广告图片或者文字，该广告共被展示了 6 次，有 2 次被浏览者点击了。每次点击的概率如下：



| 样本 | 是否被点击 | 预测点击概率 |
| :--: | :--------: | :----------: |
|  1   |     1      |     0.9      |
|  2   |     0      |     0.7      |
|  3   |     1      |     0.8      |
|  4   |     0      |     0.6      |
|  5   |     0      |     0.5      |
|  6   |     0      |     0.4      |

根据预测点击概率排序之后：

| 样本 | 是否被点击 | 预测点击概率 |
| :--: | :--------: | :----------: |
|  1   |     1      |     0.9      |
|  3   |     1      |     0.8      |
|  2   |     0      |     0.7      |
|  4   |     0      |     0.6      |
|  5   |     0      |     0.5      |
|  6   |     0      |     0.4      |

绘制 ROC 曲线：

**阈值：0.9**

1. 原本为正例的 1、3 号的样本中 3 号样本被分类错误，则 TPR = 1/2 = 0.5
2. 原本为负例的 2、4、5、6 号样本没有一个被分为正例，则 FPR = 0

**阈值：0.8**

1. 原本为正例的 1、3 号样本被分类正确，则 TPR = 2/2 = 1
2. 原本为负例的 2、4、5、6 号样本没有一个被分为正例，则 FPR = 0

**阈值：0.7**

1. 原本为正例的 1、3 号样本被分类正确，则 TPR = 2/2 = 1
2. 原本为负类的 2、4、5、6 号样本中 2 号样本被分类错误，则 FPR = 1/4 = 0.25

**阈值：0.6**

1. 原本为正例的 1、3 号样本被分类正确，则 TPR = 2/2 = 1
2. 原本为负类的 2、4、5、6 号样本中 2、4 号样本被分类错误，则 FPR = 2/4 = 0.5

**阈值：0.5**

1. 原本为正例的 1、3 号样本被分类正确，则 TPR = 2/2 = 1
2. 原本为负类的 2、4、5、6 号样本中 2、4、5 号样本被分类错误，则 FPR = 3/4 = 0.75

**阈值 0.4**

1. 原本为正例的 1、3 号样本被分类正确，则 TPR = 2/2 = 1
2. 原本为负类的 2、4、5、6 号样本全部被分类错误，则 FPR = 4/4 = 1



(0, 0.5)、(0, 1)、(0.25, 1)、(0.5, 1)、(0.75, 1)、(1, 1)



由 TPR 和 FPR 构成的 ROC 图像为：



![image-20230914105309023](./images/image-20230914105309023.png)




#### AUC 值



1. 我们发现：图像越靠近 (0,1) 点则模型对正负样本的辨别能力就越强
2. 我们发现：图像越靠近 (0, 1) 点则 ROC 曲线下面的面积就会越大
3. AUC 是 ROC 曲线下面的面积，该值越大，则模型的辨别能力就越强
4. AUC  范围在 [0, 1] 之间
5. 当 AUC= 1 时，该模型被认为是完美的分类器，但是几乎不存在完美分类器

> AUC 值主要评估模型对正例样本、负例样本的辨别能力.



####  **分类评估报告api**

```python
sklearn.metrics.classification_report(y_true, y_pred, labels=[], target_names=None )
  '''
  y_true：真实目标值
  y_pred：估计器预测目标值
  labels:指定类别对应的数字
  target_names：目标类别名称
  return：每个类别精确率与召回率
  '''
```



####  **AUC计算API**

```
from sklearn.metrics import roc_auc_score
  sklearn.metrics.roc_auc_score(y_true, y_score)
    计算ROC曲线面积，即AUC值
    y_true：每个样本的真实类别，必须为0(反例),1(正例)标记
    y_score：预测得分，可以是正例的估计概率、置信值或者分类器方法的返回值
```





## 【实践】电信客户流失预测

**学习目标：**

1.了解案例的背景信息

2.知道案例的处理流程

3.动手实现电信客户流失案例的代码




### 数据集介绍

- 流失用户指的使用过产品因为某些原因不再使用该产品。随着产品的更新迭代，都会存在一定的流失情况，这时正常现象。流失用户的比例和变化趋势能够反映该产品当前是否存在问题以及未来的发展趋势。
- 当用户群体庞大时，有限的人力和精力不能为每个用户都投入大量的时间。如果公司可以预测哪些用户可能提前流失，这样就能将主要精力聚焦于这些用户，实施有效的用户挽留策略，提高用户粘性。
- 本项目旨在通过分析特征属性确定用户流失的原因，以及哪些因素可能导致用户流失。建立预测模型来判断用户是否流失，并提出用户流失预警策略。
- 具体数据说明如下：数据集中总计7043条数据，21个特征字段，最终分类特征为Churn：用户是否流失，具体内容如下所示：
  customerID：用户ID
  gender：性别
  SeniorCitizen：是否是老人
  Partner：是否有伴侣
  Dependents：是否有需要抚养的孩子
  tenure：任职
  PhoneService：是否办理电话服务
  MultipleLines：是否开通了多条线路
  InternetService：是否开通网络服务和开通的服务类型（光纤、电话拨号）
  TechSupport：是否办理技术支持服务
  OnlineBackup：是否办理在线备份服务
  OnlineSecurity：是否办理在线安全服务
  DeviceProtection：是否办理设备保护服务
  StreamingTV：是否办理电视服务
  StreamingMovies：是否办理电影服务
  Contract：签订合约的时长
  PaperlessBilling：是否申请了无纸化账单
  PaymentMethod：付款方式（电子支票、邮寄支票、银行自动转账、信用卡自动转账）
  MonthlyCharges：月消费
  TotalCharges：总消费
  Churn：用户是否流失

### 处理流程

1、数据基本处理

 	查看数据的基本信息

​	对类别数据数据进行one-hot处理

​	查看标签分布情况

2、特征筛选

​	分析哪些特征对标签值影响大

​	初步筛选出对标签影响比较大的特征，形成x、y

3、模型训练

​	模型训练

​	交叉验证网格搜索等

4、模型评估

​	精确率

​	Roc_AUC指标计算

###  案例实现





## 作业

1. 使用思维导图总结逻辑回归的内容



2. 理解分类评估方法并进行详细的描述



3.动手实现癌症分类和电信用户流失案例(数据处理，特征工程，CV。。。。)
